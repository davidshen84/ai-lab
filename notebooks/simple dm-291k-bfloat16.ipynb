{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d0c64d7-4f0c-460a-9a06-875fd9628954",
   "metadata": {},
   "source": [
    "# Resources\n",
    "\n",
    "Here are the main resource I relied on when creating this notebook\n",
    "\n",
    "- [Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239)\n",
    "- [Diffusion Models - Live Coding Tutorial](https://youtu.be/S_il77Ttrmg?si=GiwY7utZ638VRBDP)\n",
    "- [How Diffusion Models Work](https://learn.deeplearning.ai/courses/diffusion-models/lesson/1/introduction)\n",
    "\n",
    "\n",
    "And, of course, searching around the Internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54177dc-355f-47f9-b066-bfa75e22d3d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import flax\n",
    "import jax\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow import keras as K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224816ab-8bcf-499b-9067-d4e2ca1d87a2",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca1ae9f-ac7d-4998-a538-d1cecb58abdb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_rescaling = K.layers.Rescaling(scale=1.0 / 127.5, offset=-1)\n",
    "\n",
    "\n",
    "def prepare_iamge(x):\n",
    "    \"\"\"crop the image to 27x27\"\"\"\n",
    "    return tf.image.crop_to_bounding_box(image_rescaling(x), 1, 1, 27, 27)\n",
    "\n",
    "\n",
    "(sample,) = tfds.load(\"mnist\", split=[\"train[:8]\"])\n",
    "sample = sample.map(lambda x: {\"image\": prepare_iamge(x[\"image\"]), \"label\": x[\"label\"]})\n",
    "\n",
    "fig, axes = plt.subplots(2, 4, figsize=(6, 3))\n",
    "for ax, x in zip(axes.flatten(), (x for x in sample.as_numpy_iterator())):\n",
    "    ax.imshow(x[\"image\"], cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "    ax.set_title(x[\"label\"])\n",
    "\n",
    "X = np.array([x[\"image\"] for x in sample.as_numpy_iterator()])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bbac0f",
   "metadata": {},
   "source": [
    "# U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e5a8e8-c56d-42b0-a2b5-ae7b751835f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Optional, Sequence\n",
    "\n",
    "from flax import linen as nn\n",
    "from flax.linen.module import compact\n",
    "from jax import numpy as jnp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b989eac-d998-4311-b2d7-5ff0fd79cc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng_root = jax.random.PRNGKey(0)\n",
    "rng_keys = [\"noise\", \"dropout\"]\n",
    "(rng,) = jax.random.split(rng_root, 1)\n",
    "\n",
    "\n",
    "def update_rngs(rng: jax.random.PRNGKey, rng_keys):\n",
    "    rng, *rngs = jax.random.split(rng, len(rng_keys) + 1)\n",
    "    rngs = {k: rngs[i] for i, k in enumerate(rng_keys)}\n",
    "\n",
    "    return rng, rngs\n",
    "\n",
    "\n",
    "rng, rngs = update_rngs(rng, rng_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d0089b-f918-4425-9c5a-d8b20594766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    features: int\n",
    "    kernel_size: [int, int] = (3, 3)\n",
    "\n",
    "    dtype: Any = jnp.float32\n",
    "\n",
    "    @compact\n",
    "    def __call__(self, x: jax.Array, train: bool = False):\n",
    "        return nn.Sequential(\n",
    "            [\n",
    "                nn.Conv(self.features, kernel_size=self.kernel_size, dtype=self.dtype),\n",
    "                nn.relu,\n",
    "                nn.Conv(self.features, kernel_size=self.kernel_size, dtype=self.dtype),\n",
    "                nn.relu,\n",
    "                nn.BatchNorm(use_running_average=not train, param_dtype=jnp.float32),\n",
    "            ]\n",
    "        )(x)\n",
    "\n",
    "\n",
    "model = ConvBlock(5, dtype=jnp.bfloat16)\n",
    "variables = model.init(rng, jnp.empty_like(X))\n",
    "y = model.apply(variables, X)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81897139-ad15-4e89-9473-41203c5fa9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearnedTimeEmbed(nn.Module):\n",
    "    L: int\n",
    "    d_model: int\n",
    "\n",
    "    dtype: Any = jnp.float32\n",
    "\n",
    "    @compact\n",
    "    def __call__(self, t: Sequence[int]):\n",
    "        embeds = nn.Embed(self.L, self.d_model, dtype=self.dtype)(jnp.array(t))\n",
    "\n",
    "        return embeds[:, None, None, ...]\n",
    "\n",
    "\n",
    "model = LearnedTimeEmbed(100, 5, dtype=jnp.bfloat16)\n",
    "variables = model.init(rng, t=[0])\n",
    "y = model.apply(variables, t=[0, 1])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d887ad9b-ff35-4b76-a3c0-bae2b3e94819",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownBlock(nn.Module):\n",
    "    features: int\n",
    "\n",
    "    strides: [int, int] = (2, 2)  # down size factor\n",
    "    kernel_size: [int, int] = (3, 3)\n",
    "    pool_fn: Callable = nn.max_pool\n",
    "\n",
    "    dtype: Any = jnp.float32\n",
    "\n",
    "    @compact\n",
    "    def __call__(self, x: jax.Array, train: bool = False) -> jax.Array:\n",
    "        skip = ConvBlock(self.features, self.kernel_size, dtype=self.dtype)(x, train)\n",
    "        down = self.pool_fn(skip, window_shape=self.strides, strides=self.strides)\n",
    "\n",
    "        return down, skip\n",
    "\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    features: int\n",
    "\n",
    "    kernel_size: [int, int]\n",
    "    strides: [int, int]\n",
    "\n",
    "    dtype: Any = jnp.float32\n",
    "\n",
    "    @compact\n",
    "    def __call__(\n",
    "        self, x: jax.Array, skip: jax.Array, time_embed: jax.Array, train: bool = False\n",
    "    ) -> jax.Array:\n",
    "        up = nn.ConvTranspose(\n",
    "            self.features,\n",
    "            kernel_size=self.kernel_size,\n",
    "            strides=self.strides,\n",
    "            dtype=self.dtype,\n",
    "        )(x)\n",
    "        up = up + nn.relu(nn.Dense(up.shape[-1], dtype=self.dtype)(time_embed))\n",
    "        up = jnp.concatenate([up, skip], axis=-1)\n",
    "        up = ConvBlock(self.features, self.kernel_size, dtype=self.dtype)(up, train)\n",
    "\n",
    "        return up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5377451c-94ba-4fb3-adfa-82b6f0b8205d",
   "metadata": {},
   "outputs": [],
   "source": [
    "down_block = DownBlock(3, strides=(3, 3))\n",
    "variables = down_block.init(rng, jnp.empty((27, 27, 1)))\n",
    "y, y_skip = down_block.apply(variables, jnp.ones((27, 27, 1)))\n",
    "print(y.shape)\n",
    "print(y_skip.shape)\n",
    "\n",
    "up_block = UpBlock(3, kernel_size=(3, 3), strides=(3, 3))\n",
    "variables = up_block.init(\n",
    "    rng, jnp.empty_like(y), jnp.empty_like(y_skip), jnp.empty((1, 1))\n",
    ")\n",
    "y = up_block.apply(variables, y, y_skip, jnp.ones((1, 1)))\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb908d1-9f34-4bf9-a679-12f2cd481fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    T: int  # total time step number\n",
    "    kernel_size: [int, int] = (3, 3)\n",
    "    strides: [int, int] = (2, 2)\n",
    "\n",
    "    dtype: Any = jnp.float32\n",
    "\n",
    "    @compact\n",
    "    def __call__(\n",
    "        self, x: jax.Array, t: Sequence[int], train: bool = False\n",
    "    ) -> jax.Array:\n",
    "        assert len(x.shape) == 4, f\"image shape {x.shape} != 4\"\n",
    "        assert (\n",
    "            len(t) == x.shape[0]\n",
    "        ), f\"image batch size {x.shape[0]} != embed size {len(t)}\"\n",
    "\n",
    "        time_embeds = LearnedTimeEmbed(self.T, 64, dtype=self.dtype)\n",
    "\n",
    "        # down sampling\n",
    "        down16, skip16 = DownBlock(\n",
    "            16, kernel_size=(3, 3), strides=(3, 3), dtype=self.dtype\n",
    "        )(x, train)\n",
    "        down32, skip32 = DownBlock(\n",
    "            32, kernel_size=(3, 3), strides=(3, 3), dtype=self.dtype\n",
    "        )(down16, train)\n",
    "        down64, skip64 = DownBlock(\n",
    "            64, kernel_size=(3, 3), strides=(3, 3), dtype=self.dtype\n",
    "        )(down32, train)\n",
    "\n",
    "        # up sampling\n",
    "        up64 = UpBlock(64, kernel_size=(3, 3), strides=(3, 3), dtype=self.dtype)(\n",
    "            down64, skip64, time_embeds(t), train=train\n",
    "        )\n",
    "        up32 = UpBlock(32, kernel_size=(3, 3), strides=(3, 3), dtype=self.dtype)(\n",
    "            up64, skip32, time_embeds(t), train=train\n",
    "        )\n",
    "        up16 = UpBlock(16, kernel_size=(3, 3), strides=(3, 3), dtype=self.dtype)(\n",
    "            up32, skip16, time_embeds(t), train=train\n",
    "        )\n",
    "\n",
    "        z = nn.Conv(x.shape[-1], kernel_size=(1, 1), dtype=self.dtype)(up16)\n",
    "\n",
    "        z = nn.relu(z)\n",
    "        z = nn.BatchNorm(use_running_average=not train, param_dtype=jnp.float32)(z)\n",
    "\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e51d4d-5448-44ee-8d70-034d7051a4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet(5)\n",
    "variables = unet.init(rng, jnp.empty((1, 27, 27, 1)), [0])\n",
    "y, _ = unet.apply(variables, jnp.ones((1, 27, 27, 1)), [1], mutable=[\"batch_stats\"])\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5634ecfc-a9ec-462c-9512-f61b57be4848",
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = UNet(100, dtype=jnp.bfloat16)\n",
    "unet_var = unet.init(rng, X[:2].astype(jnp.bfloat16), [0, 0])\n",
    "y, _ = unet.apply(unet_var, X[:2], [1, 2], train=True, mutable=[\"batch_stats\"])\n",
    "\n",
    "print(y.shape)\n",
    "plt.imshow(y[0].astype(jnp.float32), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcb9345-f3f1-4640-a7b6-507a9c3ed2d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(unet.tabulate({\"params\": rng, **rngs}, X.astype(jnp.bfloat16), [0] * X.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0bbf02-fa68-43c7-8758-64e23241b0f4",
   "metadata": {},
   "source": [
    "# Diffusion Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d5509b-1b44-42fc-9830-da83ad37634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionModel:\n",
    "    total_steps: int\n",
    "    dtype: Any\n",
    "\n",
    "    def __init__(self, total_steps: int = 50, dtype: Any = jnp.float32):\n",
    "        self.total_steps = total_steps\n",
    "        self.dtype = dtype\n",
    "\n",
    "        self.betas = jnp.linspace(0.0001, 0.02, self.total_steps, dtype=self.dtype)\n",
    "        self.alphas = 1.0 - self.betas\n",
    "        self.alphas_bar = jnp.cumprod(self.alphas, axis=0)\n",
    "\n",
    "    def __call__(self, x: jax.Array, t: Sequence[int], rng: jax.Array):\n",
    "        return self.add_noise(x, t, rng)\n",
    "\n",
    "    def add_noise(self, x: jax.Array, t: Sequence[int], rng: jax.Array):\n",
    "        assert x.shape[0] == len(t), \"batch size mismatch\"\n",
    "        alphas_bar_t = self.alphas_bar[t,].reshape((-1, 1, 1, 1))\n",
    "        mean = jnp.sqrt(alphas_bar_t) * x\n",
    "        noise = jax.random.normal(rng, x.shape)\n",
    "        variance = jnp.sqrt(1.0 - alphas_bar_t) * noise\n",
    "\n",
    "        x_t = mean + variance\n",
    "\n",
    "        return x_t, noise\n",
    "\n",
    "    def ddpm(self, x: jax.Array, noise: jax.Array, t: int, rng: jax.Array):\n",
    "        B, *_ = x.shape\n",
    "        betas_t = self.betas[t,]\n",
    "        alphas_t = self.alphas[t,]\n",
    "        alphas_bar_t = self.alphas_bar[t,]\n",
    "        one_alphas_t = 1.0 - alphas_t\n",
    "        sqrt_one_alphas_bar_t = jnp.sqrt(1.0 - alphas_bar_t)\n",
    "\n",
    "        mean = (x - (one_alphas_t / sqrt_one_alphas_bar_t) * noise) / jnp.sqrt(alphas_t)\n",
    "\n",
    "        if t > 0:\n",
    "            return mean + jnp.sqrt(betas_t) * jax.random.normal(rng, x.shape)\n",
    "        else:\n",
    "            return mean\n",
    "\n",
    "    def ddim(self, x_t: jax.Array, t: int, t_p: int, noise: jax.Array):\n",
    "        ab_t = self.alphas_bar.take(t).reshape((-1, 1, 1, 1))\n",
    "        ab_p = self.alphas_bar.take(t_p).reshape((-1, 1, 1, 1))\n",
    "\n",
    "        x_0_ = jnp.sqrt(ab_p / ab_t) * (x_t - jnp.sqrt(1.0 - ab_t) * noise)\n",
    "        dir_x_t = jnp.sqrt(1.0 - ab_p) * noise\n",
    "\n",
    "        return x_0_ + dir_x_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9344f077-3bba-418d-bba7-966bf7c5274a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ddpm_samples(n: int, rng: jax.Array):\n",
    "    samples = jax.random.normal(rng, (n, 27, 27, 1), dtype=jnp.bfloat16)\n",
    "    for t in range(T - 1, -1, -1):\n",
    "        rng, rngs = update_rngs(rng, rng_keys)\n",
    "        preds = unet_apply(\n",
    "            {\"params\": state.params, \"batch_stats\": state.batch_stats},\n",
    "            samples,\n",
    "            [t] * n,\n",
    "            rngs=rngs,\n",
    "        )\n",
    "        samples = dm.ddpm(samples, preds, t, rngs[\"noise\"])\n",
    "\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f1dca7-1f73-4418-943f-e3b8917bfdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = DiffusionModel(total_steps=500, dtype=jnp.float16)\n",
    "x_t, noise = dm(jnp.stack([X[0]] * 3, axis=0), [1, 10, 20], rng)\n",
    "\n",
    "fig, axes = plt.subplots(1, 3)\n",
    "for x, ax in zip(x_t, axes.flatten()):\n",
    "    ax.imshow(x.astype(jnp.float32), cmap=\"gray\")\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88224ef5-d409-4ae2-bbff-b965b2d577f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, _ = unet.apply(unet_var, x_t, [1, 10, 20], train=True, mutable=[\"batch_stats\"])\n",
    "fig, axes = plt.subplots(1, 3)\n",
    "for x, ax in zip(pred, axes):\n",
    "    ax.imshow(x.astype(jnp.float32), cmap=\"gray\")\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b08ec3b-25a8-41fd-9b71-5cd368f7626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = dm.ddpm(x_t, pred, 498, rng=rng)\n",
    "# output = dm.ddim(x_t, 5, 15, noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2109bfff-8a68-47fc-a755-024ed4b847ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(output[0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7793dd5c-0a1d-45b0-989f-68f27c3c0efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 3, figsize=(6, 4))\n",
    "\n",
    "images = [[X[0]] * 3, x_t, noise]\n",
    "for i, i_axes in enumerate(axes):\n",
    "    for j, ax in enumerate(i_axes):\n",
    "        ax.axis(\"off\")\n",
    "        ax.imshow(images[i][j], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bcae87-bb71-4ae3-ba56-d6ab88b47560",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(noise.flatten(), density=True, label=\"truth\")\n",
    "plt.hist(pred.flatten(), density=True, label=\"preds\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7106afca-7c71-44ce-9a44-bdd90087ed60",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6c80b1-2889-4daa-ac4d-1176f4bfe95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "from functools import partial\n",
    "\n",
    "import optax  # Common loss functions and optimizers\n",
    "import orbax.checkpoint as ocp\n",
    "from clu import metrics\n",
    "from flax import struct  # Flax dataclasses\n",
    "from flax.metrics import tensorboard\n",
    "from flax.training import train_state  # Useful dataclass to keep train state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a982a1ad-c8f5-409b-94b3-57c0278714ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "@struct.dataclass\n",
    "class Metrics(metrics.Collection):\n",
    "    loss: metrics.Average.from_output(\"loss\")\n",
    "\n",
    "\n",
    "class TrainState(train_state.TrainState):\n",
    "    metrics: Metrics\n",
    "    batch_stats: Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68cd6adf-a591-42ab-a0b3-0743a5e0efc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_state(\n",
    "    module: nn.Module,\n",
    "    params: dict,\n",
    "    batch_stats: Any,\n",
    "    learning_rate: float,\n",
    "    momentum: Optional[float] = None,\n",
    "    weight_decay: Optional[float] = None,\n",
    "    warmup_steps: Optional[int] = None,\n",
    "    max_steps: Optional[int] = None,\n",
    "):\n",
    "    \"\"\"Creates an initial `TrainState`.\"\"\"\n",
    "\n",
    "    # lr_scheduler = optax.warmup_cosine_decay_schedule(\n",
    "    #     init_value=0.0,\n",
    "    #     peak_value=learning_rate,\n",
    "    #     warmup_steps=warmup_steps,\n",
    "    #     decay_steps=max_steps,\n",
    "    # )\n",
    "    tx = optax.chain(\n",
    "        optax.clip_by_global_norm(1.0),\n",
    "        # optax.adamw(learning_rate, weight_decay=weight_decay)\n",
    "        # optax.sgd(learning_rate=learning_rate, momentum=momentum)\n",
    "        optax.adam(learning_rate=learning_rate),\n",
    "    )\n",
    "\n",
    "    return TrainState.create(\n",
    "        apply_fn=module.apply,\n",
    "        params=params,\n",
    "        batch_stats=batch_stats,\n",
    "        tx=tx,\n",
    "        metrics=Metrics.empty(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaaaae9-bfd3-4093-b16b-307f96e58097",
   "metadata": {},
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(state, batch: jax.Array, noises: jax.Array, t: Sequence[int], rngs):\n",
    "    \"\"\"Train for a single step.\"\"\"\n",
    "\n",
    "    def loss_fn(params, noises):\n",
    "        preds, updates = state.apply_fn(\n",
    "            {\"params\": params, \"batch_stats\": state.batch_stats},\n",
    "            x=batch,\n",
    "            t=t,\n",
    "            rngs=rngs,\n",
    "            train=True,\n",
    "            mutable=[\"batch_stats\"],\n",
    "        )\n",
    "        assert preds.shape == noises.shape\n",
    "\n",
    "        B, *_ = batch.shape\n",
    "        preds = preds.reshape((B, -1))\n",
    "        noises = noises.reshape((B, -1))\n",
    "        loss = optax.squared_error(preds, noises).mean()\n",
    "\n",
    "        return loss, (preds, updates)\n",
    "\n",
    "    grad_fn = jax.value_and_grad(loss_fn, has_aux=True)\n",
    "    (loss, (preds, updates)), grads = grad_fn(state.params, noises)\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    state = state.replace(batch_stats=updates[\"batch_stats\"])\n",
    "    metric_updates = state.metrics.single_from_model_output(preds=preds, loss=loss)\n",
    "    metrics = state.metrics.merge(metric_updates)\n",
    "    state = state.replace(metrics=metrics)\n",
    "\n",
    "    return state, metric_updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083dc42d-42dc-42d6-b218-2e5ab32f51a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prepare training dataset\n",
    "\n",
    "(train_ds,) = tfds.load(\"mnist\", split=[\"train\"])\n",
    "batch_size = 128\n",
    "num_epochs = 500\n",
    "\n",
    "num_examples = train_ds.cardinality().numpy()\n",
    "image_rescaling = K.layers.Rescaling(scale=1.0 / 127.5, offset=-1)\n",
    "train_ds = (\n",
    "    train_ds.map(\n",
    "        lambda x: prepare_iamge(x[\"image\"]),\n",
    "        num_parallel_calls=12,\n",
    "    )\n",
    "    .cache()\n",
    "    .repeat(num_epochs)\n",
    "    .shuffle(num_examples * 3)\n",
    "    .batch(batch_size, drop_remainder=True)\n",
    "    .prefetch(4)\n",
    ")\n",
    "\n",
    "max_steps = train_ds.cardinality().numpy()\n",
    "print(f\"max steps = {max_steps}\")\n",
    "steps_per_epoch = max_steps // num_epochs\n",
    "print(f\"steps per epoch = {steps_per_epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33681a58-1ab8-466d-8a73-7a6243a3c654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init. model and state\n",
    "\n",
    "learning_rate = 1.5e-4\n",
    "T = 500\n",
    "\n",
    "unet = UNet(T, dtype=jnp.bfloat16)\n",
    "unet_apply = jax.jit(unet.apply)\n",
    "variables = unet.init({\"params\": rng, **rngs}, jnp.empty((1, 27, 27, 1), dtype=jnp.bfloat16), t=[0])\n",
    "state = create_train_state(\n",
    "    unet,\n",
    "    variables[\"params\"],\n",
    "    variables[\"batch_stats\"],\n",
    "    learning_rate,\n",
    "    warmup_steps=int(0.2 * max_steps),\n",
    "    max_steps=max_steps,\n",
    ")\n",
    "\n",
    "dm = DiffusionModel(T, dtype=jnp.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc46196b-acc6-4621-9876-24ccccc452af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Debug blocks\n",
    "\n",
    "The following few blocks are for debug only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8ba713-48f4-482d-8c12-332a6e8a1360",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_t, noises = dm(X[:2], [3, 4], rng)\n",
    "\n",
    "_, metrics = train_step(state, x_t, noises, [3, 4], rngs=rngs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b8191d-012b-4c9f-983b-88b5225e1299",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_iter = train_ds.take(5).as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f315f3-9701-465a-bcfc-e53e8e82fb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = train_ds_iter.next()\n",
    "batch.shape\n",
    "batch_image = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c299c01-1de3-43a5-a200-cb7b6347c374",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng, rngs = update_rngs(rng, rng_keys)\n",
    "ts = jax.random.randint(rng, (batch_image.shape[0],), 0, T)\n",
    "x_t, noises = dm(batch_image, ts, rng)\n",
    "state, metric_updates = train_step(state, x_t, noises, ts, rngs)\n",
    "metric_updates.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccb1c3e-d8c8-4cb8-a128-4dce7497d5ce",
   "metadata": {},
   "source": [
    "# Training\n",
    "\n",
    "Finally, let's give the model a name, then we can start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497f25ac-35e1-4e5f-8691-0b79438927b0",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"dm-291k-bfloat16\"\n",
    "model_checkpoint = datetime.now().strftime(f\"{model_name}_%Y%m%d-%H%M\")\n",
    "# model_checkpoint = \"dm-291k-bfloat16_20240423-0149\"\n",
    "checkpoint_path = f\"{os.getcwd()}/checkpoint/{model_checkpoint}\"\n",
    "print(\n",
    "    f\"\"\"model name: {model_name},\n",
    "checlpoint path: {checkpoint_path}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "rng_root = jax.random.PRNGKey(0)\n",
    "rng_keys = [\"noise\"]\n",
    "(rng,) = jax.random.split(rng_root, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740662dc-9915-43c8-bf7a-0d0cafe1f96d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "log_dir = f\"tb-log/{model_name}\"\n",
    "\n",
    "summary_writer = tf.summary.create_file_writer(f\"{log_dir}/{model_checkpoint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c59b84-a3a3-43d3-8034-b8d6f147eb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "%tensorboard --logdir={log_dir} --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f20ee88-2ade-4882-8300-9fb32fe1e0ee",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "with ocp.CheckpointManager(\n",
    "    checkpoint_path,\n",
    "    options=ocp.CheckpointManagerOptions(max_to_keep=4, create=True),\n",
    "    item_handlers={\n",
    "        \"state\": ocp.StandardCheckpointHandler(),\n",
    "        \"config\": ocp.JsonCheckpointHandler(),\n",
    "    },\n",
    ") as checkpoint_manager:\n",
    "\n",
    "    restored_step = 0\n",
    "    if checkpoint_manager.latest_step():\n",
    "        restored_checkpoint = checkpoint_manager.restore(\n",
    "            checkpoint_manager.latest_step(),\n",
    "            items={\"state\": state, \"config\": None},\n",
    "        )\n",
    "        state = restored_checkpoint[\"state\"]\n",
    "        restored_step = checkpoint_manager.latest_step()\n",
    "\n",
    "    print(f\"last step: {restored_step}\")\n",
    "    steps_per_checkpoint = 100\n",
    "    train_stop_step = np.min([50_000, max_steps])\n",
    "    train_steps = train_stop_step - restored_step\n",
    "    print(f\"traning epochs: ~ {train_steps // steps_per_epoch}\")\n",
    "\n",
    "    with summary_writer.as_default():\n",
    "        for step, batch in tqdm(\n",
    "            enumerate(train_ds.take(train_steps).as_numpy_iterator()),\n",
    "            desc=\"training progress\",\n",
    "            initial=restored_step,\n",
    "            total=max_steps,\n",
    "        ):\n",
    "            rng, rngs = update_rngs(rng, rng_keys)\n",
    "            batch_image = batch\n",
    "\n",
    "            B, *_ = batch_image.shape\n",
    "            t = jax.random.randint(rng, (B,), 0, T)\n",
    "            batch_image_t, noise = dm(batch_image, t, rng)\n",
    "            state, metric_updates = train_step(state, batch_image_t, noise, t, rngs)\n",
    "            current_step = restored_step + step\n",
    "\n",
    "            if current_step % steps_per_checkpoint == 0:\n",
    "                checkpoint_manager.save(\n",
    "                    current_step,\n",
    "                    args=ocp.args.Composite(\n",
    "                        state=ocp.args.StandardSave(state), config=ocp.args.JsonSave({})\n",
    "                    ),\n",
    "                )\n",
    "\n",
    "                for m, v in metric_updates.compute().items():\n",
    "                    tf.summary.scalar(m, v, current_step)\n",
    "\n",
    "            if current_step % steps_per_epoch == 0:\n",
    "                samples = ddpm_samples(3, rng)\n",
    "                tf.summary.image(\"samples\", samples, current_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cdce38-8d75-4b90-8744-6618a8fc820c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ocp.CheckpointManager(\n",
    "    checkpoint_path,\n",
    "    options=ocp.CheckpointManagerOptions(max_to_keep=4, create=True),\n",
    "    item_handlers={\n",
    "        \"state\": ocp.StandardCheckpointHandler(),\n",
    "        \"config\": ocp.JsonCheckpointHandler(),\n",
    "    },\n",
    ") as checkpoint_manager:\n",
    "\n",
    "    restored_step = 0\n",
    "    if checkpoint_manager.latest_step():\n",
    "        restored_checkpoint = checkpoint_manager.restore(\n",
    "            checkpoint_manager.latest_step(),\n",
    "            items={\"state\": state, \"config\": None},\n",
    "        )\n",
    "        state = restored_checkpoint[\"state\"]\n",
    "        restored_step = checkpoint_manager.latest_step()\n",
    "\n",
    "    print(f\"last step: {restored_step}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bea677-0c2e-4e1c-8db4-45915cf1a139",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "denoised_images = ddpm_samples(25, rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6967d8a-09f3-40c8-b9d5-3a71ab658d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 5\n",
    "cols = 5\n",
    "\n",
    "# Create a figure and subplots\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(8, 8))\n",
    "\n",
    "# Plot each image on a separate subplot\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        index = i * cols + j\n",
    "        axes[i, j].imshow(denoised_images[index], cmap=\"gray\")\n",
    "        axes[i, j].set_title(index)\n",
    "        axes[i, j].set_xticks([])\n",
    "        axes[i, j].set_yticks([])\n",
    "\n",
    "# Adjust spacing and layout\n",
    "fig.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a98f30d-64f8-4c34-8e4c-2c2289baeec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "denoised_images = []\n",
    "samples = jax.random.normal(rng, (30, 27, 27, 1))\n",
    "step_size = 20\n",
    "inference_time_steps = list(range(T - 1, 0, -step_size)) + [0]\n",
    "# print(inference_time_steps)\n",
    "for i, t in enumerate(inference_time_steps[:-1]):\n",
    "    rng, rngs = update_rngs(rng, rng_keys)\n",
    "    pred_noise = unet.apply(\n",
    "        {\"params\": state.params, \"batch_stats\": state.batch_stats},\n",
    "        samples,\n",
    "        [t] * samples.shape[0],\n",
    "        rngs=rngs,\n",
    "    )\n",
    "\n",
    "    samples = dm.ddim(samples, t, inference_time_steps[i + 1], pred_noise)\n",
    "    denoised_images.append(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde7532d-da76-4d6b-87df-f3b3edf95d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = 3\n",
    "cols = 10\n",
    "\n",
    "# Create a figure and subplots\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(12, 4))\n",
    "\n",
    "# Plot each image on a separate subplot\n",
    "for i in range(rows):\n",
    "    for j in range(cols):\n",
    "        index = i * cols + j\n",
    "        axes[i, j].imshow(denoised_images[-1][index], cmap=\"gray\")\n",
    "        axes[i, j].set_title(index)\n",
    "        axes[i, j].set_xticks([])\n",
    "        axes[i, j].set_yticks([])\n",
    "\n",
    "# Adjust spacing and layout\n",
    "fig.tight_layout()\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96afea2-90e4-426e-adbc-33a32a5b6c28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
